{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-15T08:14:26.252656Z",
     "start_time": "2024-03-15T08:14:26.249396Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import roc_auc_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class MovieLensDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, ratings):\n",
    "        super().__init__()\n",
    "        data = ratings.copy().to_numpy()\n",
    "        self.items = data[:, :2].astype(np.int32) - 1\n",
    "        self.targets = self.__preprocess_targets(data[:, 2]).astype(np.float32)\n",
    "        self.field_dims = np.max(self.items, axis=0) + 1\n",
    "        self.user_field_idx = np.array((0,), dtype=np.int64)\n",
    "        self.item_field_idx = np.array((1,), dtype=np.int64)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.targets.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.items[idx], self.targets[idx]\n",
    "    \n",
    "    def __preprocess_targets(self, target):\n",
    "        target = target / 5.\n",
    "        return target\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T08:14:26.268791Z",
     "start_time": "2024-03-15T08:14:26.265Z"
    }
   },
   "id": "38c5c172fac54ba9",
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class MultiLayerPerceptron(torch.nn.Module):\n",
    "    def __init__(self, input_dim, embed_dims, dropout, output_layer=True):\n",
    "        super().__init__()\n",
    "        layers = list()\n",
    "        for embed_dim in embed_dims:\n",
    "            layers.append(torch.nn.Linear(input_dim, embed_dim))\n",
    "            layers.append(torch.nn.BatchNorm1d(embed_dim))\n",
    "            layers.append(torch.nn.ReLU())\n",
    "            layers.append(torch.nn.Dropout(p=dropout))\n",
    "            input_dim = embed_dim\n",
    "        if output_layer:\n",
    "            layers.append(torch.nn.Linear(input_dim, 1))\n",
    "        self.mlp = torch.nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.mlp(x)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T08:14:26.273287Z",
     "start_time": "2024-03-15T08:14:26.270151Z"
    }
   },
   "id": "8842e9081ece6be2",
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class FeatureEmbedding(torch.nn.Module):\n",
    "    def __init__(self, field_dims, embed_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = torch.nn.Embedding(sum(field_dims), embed_dim)\n",
    "        self.offsets = np.array((0, *np.cumsum(field_dims)[:-1]), dtype=np.int64)\n",
    "        torch.nn.init.xavier_uniform_(self.embedding.weight.data)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + x.new_tensor(self.offsets).unsqueeze(0)\n",
    "        return self.embedding(x)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T08:14:26.279382Z",
     "start_time": "2024-03-15T08:14:26.276787Z"
    }
   },
   "id": "8575b23fd26fbf30",
   "execution_count": 42
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class NeuralCollaborativeFiltering(torch.nn.Module):\n",
    "    def __init__(self, field_dims, user_field_idx, item_field_idx, embed_dim, mlp_dims, dropout):\n",
    "        super().__init__()\n",
    "        self.user_field_idx = user_field_idx\n",
    "        self.item_field_idx = item_field_idx\n",
    "        self.embedding = FeatureEmbedding(field_dims, embed_dim)\n",
    "        self.embed_output_dim = len(field_dims) * embed_dim\n",
    "        self.mlp = MultiLayerPerceptron(self.embed_output_dim, mlp_dims, dropout, output_layer=False)\n",
    "        self.fc = torch.nn.Linear(mlp_dims[-1] + embed_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        user_x = x[:, self.user_field_idx].squeeze(1)\n",
    "        item_x = x[:, self.item_field_idx].squeeze(1)\n",
    "        x = self.mlp(x.view(-1, self.embed_output_dim))\n",
    "        gmf = user_x * item_x\n",
    "        x = torch.cat([gmf, x], dim=1)\n",
    "        x = self.fc(x).squeeze(1)\n",
    "        return torch.sigmoid(x)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T08:14:26.283825Z",
     "start_time": "2024-03-15T08:14:26.280571Z"
    }
   },
   "id": "877e9e7d9d328d9c",
   "execution_count": 43
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def train(model, optimizer, data_loader, criterion, device, log_interval=100):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    av_loss = []\n",
    "    for i, (fields, target) in enumerate(data_loader):\n",
    "        fields, target = fields.to(device), target.to(device)\n",
    "        y = model(fields)\n",
    "        loss = criterion(y, target.float())\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    loss = total_loss / log_interval\n",
    "    av_loss.append(loss)\n",
    "    total_loss = 0\n",
    "    return np.mean(av_loss)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T08:14:26.286954Z",
     "start_time": "2024-03-15T08:14:26.284441Z"
    }
   },
   "id": "ff209cda8298f265",
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def test(model, data_loader, device):\n",
    "    model.eval()\n",
    "    targets, predicts = list(), list()\n",
    "    with torch.no_grad():\n",
    "        for fields, target in data_loader:\n",
    "            fields, target = fields.to(device), target.to(device)\n",
    "            y = model(fields)\n",
    "            targets.extend(target.tolist())\n",
    "            predicts.extend(y.tolist())\n",
    "    return 5. * mean_squared_error(targets, predicts)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T08:14:26.290688Z",
     "start_time": "2024-03-15T08:14:26.288237Z"
    }
   },
   "id": "33532c473099889b",
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "ratings = pd.read_csv('../data/ml-latest-small/ratings.csv')\n",
    "dataset = MovieLensDataset(ratings)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T08:14:26.312084Z",
     "start_time": "2024-03-15T08:14:26.291327Z"
    }
   },
   "id": "9187fee3bdbd1719",
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "learning_rate = 0.001\n",
    "weight_decay = 1e-6\n",
    "batch_size = 2048\n",
    "epochs = 10\n",
    "model_name = \"ncf\"\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T08:14:26.314790Z",
     "start_time": "2024-03-15T08:14:26.312708Z"
    }
   },
   "id": "767f37ec4e44c55f",
   "execution_count": 47
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_length = int(len(dataset) * 0.8)\n",
    "valid_length = int(len(dataset) * 0.1)\n",
    "test_length = len(dataset) - train_length - valid_length\n",
    "\n",
    "train_dataset, valid_dataset, test_dataset = torch.utils.data.random_split(dataset,\n",
    "                                                                           (train_length, valid_length, test_length))\n",
    "\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=batch_size, num_workers=2)\n",
    "valid_data_loader = DataLoader(valid_dataset, batch_size=batch_size, num_workers=2)\n",
    "test_data_loader = DataLoader(test_dataset, batch_size=batch_size, num_workers=2)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T08:14:26.320714Z",
     "start_time": "2024-03-15T08:14:26.316288Z"
    }
   },
   "id": "3d0dc5f28cb6d9cb",
   "execution_count": 48
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model = NeuralCollaborativeFiltering(\n",
    "    dataset.field_dims,\n",
    "    embed_dim=64,\n",
    "    mlp_dims=(32, 32),\n",
    "    dropout=0.2,\n",
    "    user_field_idx=dataset.user_field_idx,\n",
    "    item_field_idx=dataset.item_field_idx\n",
    ").to(device)\n",
    "\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T08:14:26.455130Z",
     "start_time": "2024-03-15T08:14:26.321357Z"
    }
   },
   "id": "986062f799004f45",
   "execution_count": 49
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/Users/jaypark/anaconda3/lib/python3.11/multiprocessing/spawn.py\", line 122, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/jaypark/anaconda3/lib/python3.11/multiprocessing/spawn.py\", line 132, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'MovieLensDataset' on <module '__main__' (built-in)>\n"
     ]
    }
   ],
   "source": [
    "metric_values = []\n",
    "loss_values = []\n",
    "\n",
    "for epoch_i in tqdm(range(epochs)):\n",
    "    loss = train(model, optimizer, train_data_loader, criterion, device)\n",
    "    loss_values.append((epoch_i, loss))\n",
    "    metric_valid = test(model, valid_data_loader, device)\n",
    " \n",
    "    metric_train = test(model, train_data_loader, device)\n",
    "    metric_test = test(model, test_data_loader, device)\n",
    "\n",
    "    metric_values.append((epoch_i, metric_train, metric_valid, metric_test))"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-03-15T08:14:26.459376Z"
    }
   },
   "id": "74f42964eb5640b9",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "551e2ddd17c9b5a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
